{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d6f8e-86cb-48da-814a-66e2090a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8cb68f-66a7-45f2-8574-78156ec019bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_tfms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sprites, slabels, transform\u001b[38;5;241m=\u001b[39mdefault_tfms, null_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, argmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msprites \u001b[38;5;241m=\u001b[39m sprites\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mCustomDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(Dataset):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sprites, slabels, transform\u001b[38;5;241m=\u001b[39m\u001b[43mdefault_tfms\u001b[49m, null_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, argmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msprites \u001b[38;5;241m=\u001b[39m sprites\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m argmax:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_tfms' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sprites, slabels, transform=default_tfms, null_context=False, argmax=False):\n",
    "        self.sprites = sprites\n",
    "        if argmax:\n",
    "            self.slabels = np.argmax(slabels, axis=1)\n",
    "        else:\n",
    "            self.slabels = slabels\n",
    "        self.transform = transform\n",
    "        self.null_context = null_context\n",
    "\n",
    "    @classmethod\n",
    "    def from_np(cls, \n",
    "                path, \n",
    "                sfilename=\"sprites_1788_16x16.npy\", lfilename=\"sprite_labels_nc_1788_16x16.npy\", transform=default_tfms, null_context=False, argmax=False):\n",
    "        sprites = np.load(Path(path)/sfilename)\n",
    "        slabels = np.load(Path(path)/lfilename)\n",
    "        return cls(sprites, slabels, transform, null_context, argmax)\n",
    "\n",
    "    # Return the number of images in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.sprites)\n",
    "    \n",
    "    # Get the image and label at a given index\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the image and label as a tuple\n",
    "        if self.transform:\n",
    "            image = self.transform(self.sprites[idx])\n",
    "            if self.null_context:\n",
    "                label = torch.tensor(0).to(torch.int64)\n",
    "            else:\n",
    "                label = torch.tensor(self.slabels[idx]).to(torch.int64)\n",
    "        return (image, label)\n",
    "    \n",
    "\n",
    "    def subset(self, slice_size=1000):\n",
    "        # return a subset of the dataset\n",
    "        indices = random.sample(range(len(self)), slice_size)\n",
    "        return CustomDataset(self.sprites[indices], self.slabels[indices], self.transform, self.null_context)\n",
    "\n",
    "    def split(self, pct=0.2):\n",
    "        \"split dataset into train and test\"\n",
    "        train_size = int((1-pct)*len(self))\n",
    "        test_size = len(self) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(self, [train_size, test_size])\n",
    "        return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1521194-a753-4eee-8c12-0ae624bd3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(data_dir, batch_size, slice_size=None, valid_pct=0.2):\n",
    "    \"Get train/val dataloaders for classification on sprites dataset\"\n",
    "    dataset = CustomDataset.from_np(Path(data_dir), argmax=True)\n",
    "    if slice_size:\n",
    "        dataset = dataset.subset(slice_size)\n",
    "\n",
    "    train_ds, valid_ds = dataset.split(valid_pct)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=1)    \n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7204afe-83e4-4436-82bf-99e8561d2f03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloaders\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilities'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from utilities import get_dataloaders\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb604369-5759-4f80-b78d-f8760712ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sprite Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e86e1c1c-1bb4-4904-a591-90be5cd34cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * 16 * 16\n",
    "OUTPUT_SIZE = 5\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_WORKERS = 3\n",
    "CLASSES = [\"hero\", \"non-hero\", \"food\", \"spell\", \"side-facing\"]\n",
    "DATA_DIR = Path(\"./data/\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d568f5b0-393d-4eb7-9c45-523ef9e0a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a config to store the hyperparameters\n",
    "config = SimpleNamespace(\n",
    "    epochs=2,\n",
    "    batch_size=128,\n",
    "    lr=1e-5,\n",
    "    dropout=0.5,\n",
    "    slice_size=10_000,\n",
    "    valid_pct=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113bc6d-b5e2-4b9f-8689-d4080a327516",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model\n",
    "\n",
    "def train_model(config):\n",
    "    \"Train a model with a given config\"\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"dlai_intro\",\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Get the data\n",
    "    train_dl, valid_dl = get_dataloaders(DATA_DIR, \n",
    "                                         config.batch_size, \n",
    "                                         config.slice_size, \n",
    "                                         config.valid_pct)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "    # A simple MLP model\n",
    "    model = get_model(config.dropout)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    example_ct = 0\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs), total=config.epochs):\n",
    "        model.train()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(images)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/epoch\": epoch + 1,\n",
    "                \"train/example_ct\": example_ct\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "        # Compute validation metrics, log images on last epoch\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func)\n",
    "        # Compute train and validation metrics\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/val_accuracy\": accuracy\n",
    "        }\n",
    "        wandb.log(val_metrics)\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
